{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3953821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Data Preprocessing and Feature Engineering\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "#Model Selection and Validation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f461cc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                                               text\n",
       "0       0  1467810369  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  1467810672  is upset that he can't update his Facebook by ...\n",
       "2       0  1467810917  @Kenichan I dived many times for the ball. Man...\n",
       "3       0  1467811184    my whole body feels itchy and like its on fire \n",
       "4       0  1467811193  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding=\"ISO-8859-1\",names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "df = df.dropna()\n",
    "del df[\"flag\"]\n",
    "del df[\"user\"]\n",
    "del df[\"date\"]\n",
    "if (len(df[\"target\"].unique()) == 1):\n",
    "    del df[\"target\"]\n",
    "else:\n",
    "    print(df[\"target\"].unique())\n",
    "df.head()\n",
    "train_tweets = df.sample(frac = 0.8)\n",
    " \n",
    "# Creating dataframe with\n",
    "# rest of the 20% values\n",
    "test_tweets = df.drop(train_tweets.index)\n",
    "\n",
    "#We have train and test, now we need to...\n",
    "# Today's goal: Get a model, train it, test it\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5809894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not even mildly tanning today may need fake bake tan this years just remind me not to go too orange\n",
      "not even mildly tanning today, may need fake bake tan this years, just remind me not to go too orange \n"
     ]
    }
   ],
   "source": [
    "def form_sentence(tweet):\n",
    "    tweet_blob = TextBlob(tweet)\n",
    "    return ' '.join(tweet_blob.words)\n",
    "\n",
    "print(form_sentence(train_tweets['text'].iloc[10]))\n",
    "print(train_tweets['text'].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10507db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['even', 'mildli', 'tan', 'today', 'may', 'need', 'fake', 'bake', 'tan', 'year', 'remind', 'go', 'orang']\n",
      "not even mildly tanning today, may need fake bake tan this years, just remind me not to go too orange \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "def no_user_alpha(tweet):\n",
    "    tweet_list = [ele for ele in tweet.split() if ele != 'user']\n",
    "    clean_tokens = [t for t in tweet_list if re.match(r'[^\\W\\d]*$', t)]\n",
    "    clean_s = ' '.join(clean_tokens)\n",
    "    clean_mess = [word for word in clean_s.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean_mess\n",
    "print(no_user_alpha(form_sentence(train_tweets['text'].iloc[10])))\n",
    "print(train_tweets['text'].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9a72cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['even', 'mildly', 'tanning', 'today', 'may', 'need', 'fake', 'bake', 'tan', 'years', 'remind', 'go', 'orange', 'thomas']\n",
      "not even mildly tanning today, may need fake bake tan this years, just remind me not to go too orange @thomas\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "def no_user_alpha(tweet):\n",
    "    tweet_list = [ele for ele in tweet.split() if ele != 'user']\n",
    "    clean_tokens = [t for t in tweet_list if re.match(r'[^\\W\\d]*$', t)]\n",
    "    clean_s = ' '.join(clean_tokens)\n",
    "    clean_mess = [word for word in clean_s.split() if word.lower() not in stopwords.words('english') and word[0] != '@']\n",
    "    return clean_mess\n",
    "print(no_user_alpha(form_sentence(train_tweets['text'].iloc[10])))\n",
    "print(train_tweets['text'].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1195b766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@bomato', 'I', 'be', 'play', 'with', 'my', 'friends', 'with', 'whom', 'I', 'use', 'to', 'play,', 'when', 'you', 'call', 'me', 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "def normalization(tweet_list):\n",
    "        lem = WordNetLemmatizer()\n",
    "        normalized_tweet = []\n",
    "        for word in tweet_list:\n",
    "            normalized_text = lem.lemmatize(word,'v')\n",
    "            normalized_tweet.append(normalized_text)\n",
    "        return normalized_tweet\n",
    "    \n",
    "tweet_list = 'I was playing with my friends with whom I used to play, when you called me yesterday'.split()\n",
    "print(normalization(tweet_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ddb5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer='word')),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "243443b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.79     70022\n",
      "           4       0.73      0.80      0.76     57978\n",
      "\n",
      "    accuracy                           0.77    128000\n",
      "   macro avg       0.77      0.78      0.77    128000\n",
      "weighted avg       0.78      0.77      0.78    128000\n",
      "\n",
      "[[52696 17326]\n",
      " [11484 46494]]\n",
      "0.774921875\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(train_tweets['text'], train_tweets['target'], test_size=0.2)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "print(classification_report(predictions,label_test))\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c63ea80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553952     0\n",
       "1262353    4\n",
       "739836     0\n",
       "518296     0\n",
       "1517863    4\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853ae65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
